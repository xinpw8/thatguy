wandb:
  entity: xinpw8
  project: pokemon
  group: ~

debug:
  env:
    headless: False
    stream_wrapper: False
    init_state: "victory_road" # "fuchsia_have_gyarados_surf_strength"
    state_dir: pyboy_states
    max_steps: 20480
    log_frequency: 1
    disable_wild_encounters: False
    disable_ai_actions: True
    use_global_map: False
    reduce_res: True
    animate_scripts: True
    save_state: False
    auto_next_elevator_floor: True 
    auto_solve_strength_puzzles: True
  train:
    device: cuda
    compile: False
    compile_mode: default
    num_envs: 1
    envs_per_worker: 1
    num_workers: 1
    env_batch_size: 128
    env_pool: True
    zero_copy: False
    batch_size: 128
    minibatch_size: 4
    batch_rows: 4
    bptt_horizon: 2
    total_timesteps: 100_000_000
    save_checkpoint: True
    checkpoint_interval: 4
    save_overlay: True
    overlay_interval: 1
    verbose: False
    env_pool: False
    load_optimizer_state: False
    async_wrapper: False
    archive_states: False

env:
  headless: True
  save_final_state: True
  print_rewards: True
  video_dir: video
  state_dir: pyboy_states
  init_state: victory_road # victory_road_4 # fuchsia_have_gyarados_surf_strength
  action_freq: 24
  max_steps: 20480
  save_video: False
  fast_video: False
  frame_stacks: 1
  perfect_ivs: True
  reduce_res: True
  two_bit: True
  log_frequency: 2000
  auto_flash: True
  disable_wild_encounters: False # True
  disable_ai_actions: False
  auto_teach_cut: True
  auto_use_cut: True
  auto_use_surf: False # True
  auto_teach_surf: True
  auto_teach_strength: True
  auto_solve_strength_puzzles: True
  auto_skip_to_elite_4: True # directly paths from victory road to engaging Loreli
  auto_remove_all_nonuseful_items: True
  auto_pokeflute: True
  auto_next_elevator_floor: False
  skip_safari_zone: True
  infinite_money: True
  use_global_map: False
  save_state: True
  animate_scripts: True
  exploration_inc: 1.0
  exploration_max: 1.0
  max_steps_scaling: 0 # 0.2 # every 10 events or items gained, multiply max_steps by 2
  map_id_scalefactor: 5.0 # multiply map ids whose events have not been completed by 5




train:
  seed: 1
  torch_deterministic: True
  device: cuda
  compile: True # False # True # True
  compile_mode: "reduce-overhead"
  float32_matmul_precision: "high"
  total_timesteps: 100_000_000_000
  batch_size: 65536 # 32768 # 65536 
  minibatch_size: 2048
  learning_rate: 2.0e-4
  anneal_lr: False
  gamma: 0.998
  gae_lambda: 0.95
  num_minibatches: 4
  update_epochs: 3
  norm_adv: True
  clip_coef: 0.1
  clip_vloss: True
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: ~
  batch_rows: 128
  bptt_horizon: 16 
  vf_clip_coef: 0.1

  num_envs: 96 # 288 # 96 # 288 # 288 # 144 # 288
  num_workers: 32 # 24 # 32 # 24 # 24 # 8 # 24
  env_batch_size: 36
  env_pool: True
  zero_copy: False

  verbose: False
  data_dir: runs
  save_checkpoint: False
  checkpoint_interval: 200
  save_overlay: True
  overlay_interval: 100
  cpu_offload: False
  pool_kernel: [0]
  load_optimizer_state: False
  use_rnn: True
  async_wrapper: True # False # True
  archive_states: True
  swarm: True # False # True

wrappers:
  empty:
    - episode_stats.EpisodeStatsWrapper: {}

  baseline:
    - stream_wrapper.StreamWrapper:
        user: bet_bet_bet
    - exploration.DecayWrapper:
        step_forgetting_factor:
          npc: 0.995
          coords: 0.9995
          map_ids: 0.995
          explore: 0.9995
          start_menu: 0.998
          pokemon_menu: 0.998
          stats_menu: 0.998
          bag_menu: 0.998
          action_bag_menu: 0.998
        forgetting_frequency: 10
    - exploration.OnResetExplorationWrapper:
        full_reset_frequency: 1
        jitter: 0
  
  finite_coords:
    - stream_wrapper.StreamWrapper:
        user: bet_bet_bet
    - exploration.MaxLengthWrapper:
        capacity: 1750
    - exploration.OnResetExplorationWrapper:
        full_reset_frequency: 1
        jitter: 0

  stream_only:
    - stream_wrapper.StreamWrapper:
        user: bet_bet_bet
    - exploration.OnResetExplorationWrapper:
        full_reset_frequency: 1
        jitter: 1

  fixed_reset_value:
    - stream_wrapper.StreamWrapper:
        user: bet_bet_bet 
    - exploration.OnResetLowerToFixedValueWrapper:
        fixed_value:
          coords: 0.33
          map_ids: 0.33
          npc: 0.33
          cut: 0.33
          explore: 0.33
    - exploration.OnResetExplorationWrapper:
        full_reset_frequency: 25
        jitter: 0
    - episode_stats.EpisodeStatsWrapper: {}

rewards:
  baseline.BaselineRewardEnv:
    reward:
  baseline.TeachCutReplicationEnv:
    reward:
      event: 1.0
      bill_saved: 5.0
      seen_pokemon: 4.0
      caught_pokemon: 4.0
      moves_obtained: 4.0
      hm_count: 10.0
      level: 1.0
      badges: 10.0
      exploration: 0.02
      cut_coords: 1.0
      cut_tiles: 1.0
      start_menu: 0.01
      pokemon_menu: 0.1
      stats_menu: 0.1
      bag_menu: 0.1

  baseline.TeachCutReplicationEnvFork:
    reward:
      event: 1.0
      bill_saved: 5.0
      moves_obtained: 4.0
      hm_count: 10.0
      badges: 10.0
      exploration: 0.02
      cut_coords: 1.0
      cut_tiles: 1.0
      start_menu: 0.01
      pokemon_menu: 0.1
      stats_menu: 0.1
      bag_menu: 0.1
      taught_cut: 10.0
      explore_npcs: 0.02
      explore_hidden_objs: 0.02

  baseline.CutWithObjectRewardsEnv:
    reward:
      event: 1.0
      bill_saved: 5.0
      seen_pokemon: 4.0
      caught_pokemon: 4.0
      moves_obtained: 4.0
      hm_count: 10.0
      level: 1.0
      badges: 10.0
      exploration: 0.02
      cut_coords: 0.0
      cut_tiles: 0.0
      start_menu: 0.00
      pokemon_menu: 0.0
      stats_menu: 0.0
      bag_menu: 0.1
      rocket_hideout_found: 5.0
      explore_hidden_objs: 0.02
      seen_action_bag_menu: 0.1
  
  baseline.CutWithObjectRewardRequiredEventsEnv:
    reward:
      event: 1.0
      seen_pokemon: 4.0
      caught_pokemon: 4.0
      moves_obtained: 4.0
      hm_count: 10.0
      level: 1.0
      badges: 5.0
      exploration: 0.02
      cut_coords: 0.0
      cut_tiles: 0.0
      start_menu: 0.0
      pokemon_menu: 0.0
      stats_menu: 0.0
      bag_menu: 0.0
      explore_hidden_objs: 0.02
      seen_action_bag_menu: 0.0
      required_event: 5.0
      required_item: 5.0
      useful_item: 1.0
      pokecenter_heal: 1.0
    
  baseline.ObjectRewardRequiredEventsEnvTilesetExploration:
    reward:
      event: 1.0
      seen_pokemon: 4.0
      caught_pokemon: 4.0
      moves_obtained: 4.0
      hm_count: 10.0
      level: 1.0
      badges: 5.0
      cut_coords: 0.0
      cut_tiles: 0.0
      start_menu: 0.0
      pokemon_menu: 0.0
      stats_menu: 0.0
      bag_menu: 0.0
      explore_hidden_objs: 0.01
      explore_signs: 0.015
      seen_action_bag_menu: 0.0
      required_event: 5.0
      required_item: 5.0
      useful_item: 1.0
      pokecenter_heal: 0.2
      exploration: 0.02
      exploration_gym: 0.025
      exploration_facility: 0 # 0.11
      exploration_plateau: 0.025
      exploration_lobby: 0.035 # for game corner
      exploration_lab: 0 # 0.15 # 0.025
      a_press: 0.0 # 0.00001
      explore_warps: 0.05
      use_surf: 0.5 # 0.05
      beat_elite_4_trainer: 50.0
      beat_champion_rival: 100.0



policies:
  multi_convolutional.MultiConvolutionalPolicy:
    policy:
      hidden_size: 512

    rnn:
      # Assumed to be in the same module as the policy
      name: MultiConvolutionalRNN
      args:
        input_size: 512
        hidden_size: 512
        num_layers: 1
